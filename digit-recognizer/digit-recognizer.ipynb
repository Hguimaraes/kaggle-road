{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Keras imports\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Labels and reshape the images\n",
    "labels = train_df['label']\n",
    "# Reshape train\n",
    "train_img = train_df.drop('label', 1).as_matrix()\n",
    "train_img = train_img.reshape(train_img.shape[0], 28, 28, 1)\n",
    "# Reshape test\n",
    "test_img = test_df.as_matrix()\n",
    "test_img = test_img.reshape(test_img.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to normalize and standartize the dataset\n",
    "def normalize(x):\n",
    "    return x/255\n",
    "\n",
    "def standartize(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    return (x - mean)/std\n",
    "\n",
    "# Apply the pre-processing\n",
    "train_img = normalize(train_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = to_categorical(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to go deep: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras model\n",
    "# (conv + relu + BN + MP)-> (conv + relu + BN + MP) --> Regular MLP\n",
    "cnn = Sequential()\n",
    "\n",
    "# 1st conv block\n",
    "cnn.add(Conv2D(32, kernel_size=(5, 5),\n",
    "    activation='relu',\n",
    "    input_shape=train_img.shape[1:]))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "# 2nd conv block\n",
    "cnn.add(Conv2D(64, kernel_size=(5, 5),activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# regular mlp\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(512, activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the CNN: 254986\n",
      "Epoch 1/60\n",
      "623/623 [==============================] - 59s - loss: 0.3719 - acc: 0.8829 - val_loss: 0.1084 - val_acc: 0.9629\n",
      "Epoch 2/60\n",
      "623/623 [==============================] - 58s - loss: 0.1489 - acc: 0.9541 - val_loss: 0.0592 - val_acc: 0.9852\n",
      "Epoch 3/60\n",
      "623/623 [==============================] - 60s - loss: 0.1212 - acc: 0.9634 - val_loss: 0.0441 - val_acc: 0.9876\n",
      "Epoch 4/60\n",
      "623/623 [==============================] - 59s - loss: 0.1044 - acc: 0.9692 - val_loss: 0.0287 - val_acc: 0.9905\n",
      "Epoch 5/60\n",
      "623/623 [==============================] - 58s - loss: 0.0915 - acc: 0.9726 - val_loss: 0.0353 - val_acc: 0.9905\n",
      "Epoch 6/60\n",
      "623/623 [==============================] - 58s - loss: 0.0876 - acc: 0.9741 - val_loss: 0.0417 - val_acc: 0.9910\n",
      "Epoch 7/60\n",
      "623/623 [==============================] - 58s - loss: 0.0789 - acc: 0.9762 - val_loss: 0.0553 - val_acc: 0.9819\n",
      "Epoch 8/60\n",
      "623/623 [==============================] - 58s - loss: 0.0819 - acc: 0.9755 - val_loss: 0.0239 - val_acc: 0.9957\n",
      "Epoch 9/60\n",
      "623/623 [==============================] - 57s - loss: 0.0721 - acc: 0.9784 - val_loss: 0.0198 - val_acc: 0.9943\n",
      "Epoch 10/60\n",
      "623/623 [==============================] - 60s - loss: 0.0677 - acc: 0.9789 - val_loss: 0.0356 - val_acc: 0.9905\n",
      "Epoch 11/60\n",
      "623/623 [==============================] - 62s - loss: 0.0688 - acc: 0.9794 - val_loss: 0.0255 - val_acc: 0.9914\n",
      "Epoch 12/60\n",
      "623/623 [==============================] - 62s - loss: 0.0691 - acc: 0.9790 - val_loss: 0.0326 - val_acc: 0.9914\n",
      "Epoch 13/60\n",
      "623/623 [==============================] - 63s - loss: 0.0630 - acc: 0.9803 - val_loss: 0.0287 - val_acc: 0.9929\n",
      "Epoch 14/60\n",
      "623/623 [==============================] - 62s - loss: 0.0585 - acc: 0.9828 - val_loss: 0.0298 - val_acc: 0.9910\n",
      "Epoch 15/60\n",
      "623/623 [==============================] - 62s - loss: 0.0592 - acc: 0.9825 - val_loss: 0.0254 - val_acc: 0.9938\n",
      "Epoch 16/60\n",
      "623/623 [==============================] - 62s - loss: 0.0583 - acc: 0.9825 - val_loss: 0.0248 - val_acc: 0.9905\n",
      "Epoch 17/60\n",
      "623/623 [==============================] - 60s - loss: 0.0565 - acc: 0.9834 - val_loss: 0.0253 - val_acc: 0.9919\n",
      "Epoch 18/60\n",
      "623/623 [==============================] - 61s - loss: 0.0525 - acc: 0.9838 - val_loss: 0.0268 - val_acc: 0.9910\n",
      "Epoch 19/60\n",
      "623/623 [==============================] - 61s - loss: 0.0580 - acc: 0.9824 - val_loss: 0.0179 - val_acc: 0.9938\n",
      "Epoch 20/60\n",
      "623/623 [==============================] - 61s - loss: 0.0529 - acc: 0.9839 - val_loss: 0.0231 - val_acc: 0.9943\n",
      "Epoch 21/60\n",
      "623/623 [==============================] - 59s - loss: 0.0542 - acc: 0.9835 - val_loss: 0.0283 - val_acc: 0.9924\n",
      "Epoch 22/60\n",
      "623/623 [==============================] - 61s - loss: 0.0513 - acc: 0.9842 - val_loss: 0.0219 - val_acc: 0.9933\n",
      "Epoch 23/60\n",
      "623/623 [==============================] - 62s - loss: 0.0492 - acc: 0.9856 - val_loss: 0.0306 - val_acc: 0.9919\n",
      "Epoch 24/60\n",
      "623/623 [==============================] - 62s - loss: 0.0491 - acc: 0.9850 - val_loss: 0.0173 - val_acc: 0.9938\n",
      "Epoch 25/60\n",
      "623/623 [==============================] - 61s - loss: 0.0479 - acc: 0.9860 - val_loss: 0.0198 - val_acc: 0.9938.\n",
      "Epoch 26/60\n",
      "623/623 [==============================] - 64s - loss: 0.0469 - acc: 0.9861 - val_loss: 0.0286 - val_acc: 0.9938\n",
      "Epoch 27/60\n",
      "623/623 [==============================] - 62s - loss: 0.0442 - acc: 0.9867 - val_loss: 0.0215 - val_acc: 0.9933\n",
      "Epoch 28/60\n",
      "623/623 [==============================] - 62s - loss: 0.0450 - acc: 0.9863 - val_loss: 0.0271 - val_acc: 0.9929\n",
      "Epoch 29/60\n",
      "623/623 [==============================] - 61s - loss: 0.0463 - acc: 0.9858 - val_loss: 0.0202 - val_acc: 0.9933\n",
      "Epoch 30/60\n",
      "623/623 [==============================] - 60s - loss: 0.0430 - acc: 0.9869 - val_loss: 0.0215 - val_acc: 0.9943\n",
      "Epoch 31/60\n",
      "623/623 [==============================] - 60s - loss: 0.0449 - acc: 0.9860 - val_loss: 0.0219 - val_acc: 0.9929\n",
      "Epoch 32/60\n",
      "623/623 [==============================] - 60s - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0356 - val_acc: 0.9910\n",
      "Epoch 33/60\n",
      "623/623 [==============================] - 61s - loss: 0.0455 - acc: 0.9860 - val_loss: 0.0185 - val_acc: 0.9938\n",
      "Epoch 34/60\n",
      "623/623 [==============================] - 60s - loss: 0.0438 - acc: 0.9862 - val_loss: 0.0214 - val_acc: 0.9933\n",
      "Epoch 35/60\n",
      "623/623 [==============================] - 60s - loss: 0.0429 - acc: 0.9876 - val_loss: 0.0160 - val_acc: 0.9962\n",
      "Epoch 36/60\n",
      "623/623 [==============================] - 60s - loss: 0.0425 - acc: 0.9869 - val_loss: 0.0187 - val_acc: 0.9933\n",
      "Epoch 37/60\n",
      "623/623 [==============================] - 60s - loss: 0.0390 - acc: 0.9885 - val_loss: 0.0168 - val_acc: 0.9952\n",
      "Epoch 38/60\n",
      "623/623 [==============================] - 61s - loss: 0.0381 - acc: 0.9881 - val_loss: 0.0204 - val_acc: 0.9933\n",
      "Epoch 39/60\n",
      "623/623 [==============================] - 60s - loss: 0.0430 - acc: 0.9870 - val_loss: 0.0220 - val_acc: 0.9910\n",
      "Epoch 40/60\n",
      "623/623 [==============================] - 60s - loss: 0.0429 - acc: 0.9872 - val_loss: 0.0179 - val_acc: 0.9948\n",
      "Epoch 41/60\n",
      "623/623 [==============================] - 60s - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0218 - val_acc: 0.9938\n",
      "Epoch 42/60\n",
      "623/623 [==============================] - 60s - loss: 0.0392 - acc: 0.9882 - val_loss: 0.0273 - val_acc: 0.9938\n",
      "Epoch 43/60\n",
      "623/623 [==============================] - 61s - loss: 0.0375 - acc: 0.9884 - val_loss: 0.0196 - val_acc: 0.9952\n",
      "Epoch 44/60\n",
      "623/623 [==============================] - 59s - loss: 0.0388 - acc: 0.9880 - val_loss: 0.0219 - val_acc: 0.9943\n",
      "Epoch 45/60\n",
      "623/623 [==============================] - 59s - loss: 0.0405 - acc: 0.9883 - val_loss: 0.0218 - val_acc: 0.9929\n",
      "Epoch 46/60\n",
      "623/623 [==============================] - 60s - loss: 0.0428 - acc: 0.9870 - val_loss: 0.0297 - val_acc: 0.9933\n",
      "Epoch 47/60\n",
      "623/623 [==============================] - 60s - loss: 0.0364 - acc: 0.9890 - val_loss: 0.0246 - val_acc: 0.9952\n",
      "Epoch 48/60\n",
      "623/623 [==============================] - 60s - loss: 0.0384 - acc: 0.9886 - val_loss: 0.0313 - val_acc: 0.9943\n",
      "Epoch 49/60\n",
      "623/623 [==============================] - 60s - loss: 0.0381 - acc: 0.9887 - val_loss: 0.0179 - val_acc: 0.9948\n",
      "Epoch 50/60\n",
      "623/623 [==============================] - 61s - loss: 0.0335 - acc: 0.9897 - val_loss: 0.0150 - val_acc: 0.9957\n",
      "Epoch 51/60\n",
      "623/623 [==============================] - 60s - loss: 0.0384 - acc: 0.9882 - val_loss: 0.0177 - val_acc: 0.9938\n",
      "Epoch 52/60\n",
      "623/623 [==============================] - 63s - loss: 0.0395 - acc: 0.9882 - val_loss: 0.0240 - val_acc: 0.9938\n",
      "Epoch 53/60\n",
      "623/623 [==============================] - 60s - loss: 0.0350 - acc: 0.9890 - val_loss: 0.0236 - val_acc: 0.9943\n",
      "Epoch 54/60\n",
      "623/623 [==============================] - 61s - loss: 0.0360 - acc: 0.9892 - val_loss: 0.0174 - val_acc: 0.9948\n",
      "Epoch 55/60\n",
      "623/623 [==============================] - 62s - loss: 0.0372 - acc: 0.9887 - val_loss: 0.0255 - val_acc: 0.9948\n",
      "Epoch 56/60\n",
      "623/623 [==============================] - 60s - loss: 0.0347 - acc: 0.9895 - val_loss: 0.0187 - val_acc: 0.9952\n",
      "Epoch 57/60\n",
      "623/623 [==============================] - 61s - loss: 0.0347 - acc: 0.9897 - val_loss: 0.0255 - val_acc: 0.9943\n",
      "Epoch 58/60\n",
      "623/623 [==============================] - 61s - loss: 0.0346 - acc: 0.9891 - val_loss: 0.0178 - val_acc: 0.9943\n",
      "Epoch 59/60\n",
      "623/623 [==============================] - 60s - loss: 0.0357 - acc: 0.9892 - val_loss: 0.0168 - val_acc: 0.9952\n",
      "Epoch 60/60\n",
      "623/623 [==============================] - 58s - loss: 0.0340 - acc: 0.9902 - val_loss: 0.0169 - val_acc: 0.9957\n",
      "[[200   0   0   0   0   0   0   0   0   0]\n",
      " [  0 257   0   0   0   0   0   0   0   0]\n",
      " [  0   0 191   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   1   0   1]\n",
      " [  0   1   0   0 193   0   0   0   0   0]\n",
      " [  0   0   0   1   0 176   0   0   2   1]\n",
      " [  0   0   0   0   1   0 221   0   0   0]\n",
      " [  0   0   0   0   0   0   0 224   0   0]\n",
      " [  0   0   0   0   0   0   0   0 190   0]\n",
      " [  0   0   0   0   0   1   0   0   0 223]]\n",
      "Test loss: 0.0168780791013\n",
      "Test accuracy: 0.995714285714\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "batch_size = 64\n",
    "epochs = 60\n",
    "\n",
    "# Split the dataset into training and test\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.05)\n",
    "for train_index, test_index in sss.split(train_img, labels):\n",
    "    x_train, x_test = train_img[train_index], train_img[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "# Image Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)\n",
    "    \n",
    "# Options for the model\n",
    "print(\"Size of the CNN: %s\" % cnn.count_params())\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.05, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
    "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))\n",
    "\n",
    "score = cnn.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "# Print the confusion matrix of the model\n",
    "pred_values = np.argmax(cnn.predict(x_test), axis = 1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis = 1), pred_values)\n",
    "print(cm)\n",
    "\n",
    "# Print metrics\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 17s    \n"
     ]
    }
   ],
   "source": [
    "predictions = cnn.predict_classes(normalize(test_img))\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions})\n",
    "submissions.to_csv(\"submission.txt\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
